{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "047c8e31-17be-4ceb-94a2-26648655bfe2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Sentiment Analysis\n",
    "#### Using Chatgpt\n",
    "- Testing on Test Set based on Prompt\n",
    "#### Using Few Shot\n",
    "- Takes train set as an input for previous examples\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "HINT: You are attempting to install a package literally named \"requirements.txt\" (which cannot exist). Consider using the '-r' flag to install the packages listed in requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement requirements.txt (from versions: none)\n",
      "ERROR: No matching distribution found for requirements.txt\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934646ab-554b-4538-9b87-38651833e9f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (0.28.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (1.26.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install openai\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "# import tiktoken\n",
    "import warnings\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73ad2c83-e5d4-4e27-aa80-bd511b2e724e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Configure OpenAI connection\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m dbutils\u001b[39m.\u001b[39msecrets\u001b[39m.\u001b[39mget(scope\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mopenai\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapi-key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m openai\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://gsk-ds.openai.azure.com/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m openai\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2023-03-15-preview\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dbutils' is not defined"
     ]
    }
   ],
   "source": [
    "#Configure OpenAI connection\n",
    "openai.api_key = dbutils.secrets.get(scope=\"openai\", key=\"api-key\")\n",
    "openai.api_base = \"https://gsk-ds.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_type = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aec5343f-416e-48c4-8785-e78118ee2316",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class OpenaiAnnotater():\n",
    "  # openai.api_key = dbutils.secrets.get(scope=\"openai\", key=\"api-key\")\n",
    "  def __init__(self, engine = \"ds-gpt-35\", temp = 0):\n",
    "    self.engine = engine\n",
    "    self.temp = temp\n",
    "\n",
    "  def question_answer(self, system_prompt, user_prompt):\n",
    "    # for prompt in pronmpts:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},{\"role\" : \"user\", \"content\" : user_prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "      engine = self.engine,\n",
    "      temperature = self.temp,\n",
    "      messages=messages,\n",
    "      max_tokens=2000\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "  \n",
    "\n",
    "  def get_completion(self, user_prompt):\n",
    "    # for prompt in pronmpts:\n",
    "    messages = [{\"role\" : \"user\", \"content\" : user_prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "      engine = self.engine,\n",
    "      temperature = self.temp,\n",
    "      messages=messages,\n",
    "      max_tokens=2000\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8036d74-9f7c-46d7-bebf-39e609481957",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "annotater  = OpenaiAnnotater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff0a128-5754-459c-9e57-0795d806cb15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_path = '/dbfs/mnt/medicalaffairs/Deepti_test/Sentiment Analysis//'\n",
    "reportname='RSV-workbook.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952fb8f0-deee-463f-b4fc-0eb6a417d519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in /local_disk0/.ephemeral_nfs/envs/pythonEnv-62fa9a48-7bcd-48e2-b8f5-36ec8c18444c/lib/python3.10/site-packages (3.1.9)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter\n",
    "# Specify the Excel file name\n",
    "out_excel_file_name = blob_path+\"RSV_Sentiment_Sample_Out.xlsx\"\n",
    "# Create an ExcelWriter object\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('tmp_out.xlsx', engine='xlsxwriter') #to write in excel - temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8586b6-4317-4687-a1da-363193fb4800",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#samples for training\n",
    "df=pd.read_excel(blob_path+reportname, sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6859b6d2-9bcc-4169-9351-ae6ff515380b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'inputs', 'prediction', 'prediction_agent',\n",
       "       'annotation', 'annotation_agent', 'vectors', 'multi_label',\n",
       "       'explanation',\n",
       "       ...\n",
       "       'risk_groups_diabetes: 534', 'sentiment_negative: 314',\n",
       "       'dis_educ_cont_rec_pos: 558', 'dis_educ_cont_rec_neg: 560',\n",
       "       'risk_groups_sleep_apnea: 565', 'driver_aware: 561',\n",
       "       'dis_educ_cont_rec_neutral: 559', 'sentiment_neutral: 315',\n",
       "       'adjuvant_unaware: 466', 'dis_educ_later: 436'],\n",
       "      dtype='object', length=149)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1edc9b51-7089-4435-9b9c-5e8c6718a5aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new= df[(df['safety_favorable: 703']==1) | (df['safety_concerned: 701']==1) | (df['safety_neutral: 702'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61db3e08-6b33-4f0c-9ef2-16800fb341e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc0d029c-66e5-4765-9028-98e0585479a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>safety_favorable: 703</th>\n",
       "      <th>safety_concerned: 701</th>\n",
       "      <th>safety_neutral: 702</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arexvy Vaccine Efficacy and Safety Season 2\\nI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Coadministration project\\nP4 pharmacy student ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CME is pulmonologist and MUN provider in large...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Questions asked at the presentation: re the RS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>No Differences in Efficacy, But Concerned for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Arexvy VE and Safety\\nSchool of Pharmacy Pharm...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>Arexvy coadmin with Fluad\\nClinical Services c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>ASO1b\\nEE said it was a good thing we didn't u...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Vaccine safety\\nEE is a pharmacy manager of an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>Local pulmonologist inquired about the safety ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ...  safety_neutral: 702\n",
       "10    Arexvy Vaccine Efficacy and Safety Season 2\\nI...  ...                    0\n",
       "16    Coadministration project\\nP4 pharmacy student ...  ...                    1\n",
       "75    CME is pulmonologist and MUN provider in large...  ...                    1\n",
       "89    Questions asked at the presentation: re the RS...  ...                    1\n",
       "118   No Differences in Efficacy, But Concerned for ...  ...                    0\n",
       "...                                                 ...  ...                  ...\n",
       "2495  Arexvy VE and Safety\\nSchool of Pharmacy Pharm...  ...                    0\n",
       "2508  Arexvy coadmin with Fluad\\nClinical Services c...  ...                    0\n",
       "2540  ASO1b\\nEE said it was a good thing we didn't u...  ...                    0\n",
       "2566  Vaccine safety\\nEE is a pharmacy manager of an...  ...                    0\n",
       "2597  Local pulmonologist inquired about the safety ...  ...                    0\n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new[['text','safety_favorable: 703','safety_concerned: 701','safety_neutral: 702']]\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6554f14a-e87e-42a6-9247-7c70c8a49747",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 4)\n",
      "(39, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_new_1, random_state=32, test_size=0.30, shuffle=True)\n",
    "\n",
    "print(df_train.shape) #this will be required for few shots only\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f82ea11-f094-4f49-8afb-f1f6549ee724",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>safety_favorable: 703</th>\n",
       "      <th>safety_concerned: 701</th>\n",
       "      <th>safety_neutral: 702</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>What data is important for community immunizer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Clear Difference in Efficacy \\nEE is family me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ...  safety_neutral: 702\n",
       "482   What data is important for community immunizer...  ...                    0\n",
       "2097  Clear Difference in Efficacy \\nEE is family me...  ...                    0\n",
       "\n",
       "[2 rows x 4 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eed7e63-1862-40df-a9da-407064aa8ae6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Chatgpt to predict sentiment on test class: df_test - no other input needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3837c379-af12-4545-9761-219a798bab2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sentiment_list= ['favorable', 'neutral', 'concerned']\n",
    "business_context=\"\"\"To understand HCP's perception of safety profile of GSK's RSV vaccine - this will help drive decision making (I.e. education)\"\"\"\n",
    "rationale=\"\"\"To understand if HCP inquire about or mention the safety of the rsv vaccine? Does HCP speak favorably of GSK's RSV vaccine. Example: \"HCP not concerned about safety profile - adverse events were as expected\". Is the HCP concerned about the safety of GSK's RSV vaccine? HCP may show concerns about the safety GSK's RSV vaccine. This could include: concerns about adverse events or any other hesitations with regards to safety. Does HCP indicates that he/ she is neutral towards GSK's RSV vaccine. Examples: \"if safety is good then patients will get the vaccine\"; \"more information on reactogenicity\"\"\"\n",
    "def get_sentiment_output(text_sentiment):\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "  Act as an AI medical expert, an automated service to identify if the sentiment in a mvoc_stmt is from \\\n",
    "  the list of sentiments mentioned in sentiment_list, separated by comma. Analyze the sentiment of mvoc_stmt while considering the business context and rationale to gain a comprehensive understanding given in business_context and rationale in next line\\\n",
    "  Businesscontext: ```{business_context}```\\\n",
    "\n",
    "  Rationale: ```{rationale}```\\\n",
    "  \n",
    "  Sentiment List: ```{sentiment_list} ```\\\n",
    "  \n",
    "  After predicting the sentiment match it with the list given in sentiment_list. \\\n",
    "  Output the matched sentiment with header 'predicted_sentiment'.   \\\n",
    "  The statement is made in the USA and delimited by triple backticks as follows: \n",
    "  \n",
    "  mVOC: ```{text_sentiment}```. \n",
    "\n",
    "  Be precise. Do not add any information which is not present in the data. Cross-check your answer before for accuracy and logical consitency. Donot output the result in commas or inverted commas\" \n",
    "\n",
    "  \"\"\"\n",
    "\n",
    " \n",
    "  response=annotater.get_completion(prompt)\n",
    "  #print(response)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b36f2f6-7e4d-4aaf-a258-2e173dcfdf29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: favorable\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'neutral'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'neutral'\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'neutral'\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: favorable\n",
      "predicted_sentiment: favorable\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'concerned'\n",
      "predicted_sentiment: 'neutral'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: 'neutral'\n",
      "predicted_sentiment: 'favorable'\n",
      "predicted_sentiment: neutral\n",
      "predicted_sentiment: 'favorable'\n"
     ]
    }
   ],
   "source": [
    "df_chatgpt_response= pd.DataFrame()\n",
    "for index, row in df_test.iterrows():\n",
    "\n",
    "  response= get_sentiment_output(row['text'])\n",
    "  #print(response)\n",
    "  df_chatgpt_response.at[index,'Text']= row['text']\n",
    "  df_chatgpt_response.at[index,'Predicted Sentiment']=response\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3abe917f-c784-44bd-9089-4c4877cbb961",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>What data is important for community immunizer...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Clear Difference in Efficacy \\nEE is family me...</td>\n",
       "      <td>favorable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Predicted Sentiment\n",
       "482   What data is important for community immunizer...             neutral\n",
       "2097  Clear Difference in Efficacy \\nEE is family me...           favorable"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_chatgpt_response['Predicted Sentiment'] = df_chatgpt_response['Predicted Sentiment'].str.replace('predicted_sentiment: ', \"\")\n",
    "df_chatgpt_response['Predicted Sentiment'] = df_chatgpt_response['Predicted Sentiment'].str.replace(\"'\", \"\")\n",
    "df_chatgpt_response.head(2)\n",
    "\n",
    "#map_to_nos = {'favorable':0, 'neutral':1, 'concerned':2}\n",
    "\n",
    "#df_chatgpt_response['Predicted Sentiment'] = df_chatgpt_response['Predicted Sentiment'].map(map_to_nos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c11b66-c218-4b6b-a870-2f800fdea67a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_chatgpt_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9716c56-70af-4dab-a99e-784081c41878",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceea6e3a-e164-41b3-a58a-4dde81d060ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d9a895-521f-4564-b020-7a594b627945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28211fae-2de7-46bb-86a2-640e602c0df4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "#Actual values\n",
    "df_test1 = df_test.rename(columns={'safety_favorable: 703': 'favorable', 'safety_neutral: 702': 'neutral', 'safety_concerned: 701' : 'concerned' })\n",
    "print(len(df_test1))\n",
    "'''\n",
    "melted_df= df_test1.melt(id_vars=[\"text\"], \n",
    "        var_name=\"Actual Sentiment\"\n",
    "        )\n",
    "\n",
    "'''\n",
    "for index, row in df_test1.iterrows():\n",
    "  if row['favorable']==1:\n",
    "      df_test1.at[index, 'Actual Sentiment'] = 'favorable'\n",
    "  elif row['neutral']==1:\n",
    "      df_test1.at[index, 'Actual Sentiment'] = 'neutral'\n",
    "  elif row['concerned']==1:\n",
    "      df_test1.at[index, 'Actual Sentiment'] = 'concerned'\n",
    "  else:\n",
    "    pass \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd9c6c8-140b-4a51-9afa-39192457d25b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test1['Actual Sentiment'].tolist(), df_chatgpt_response['Predicted Sentiment'].tolist())\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37cb0095-0c84-4d10-9838-aa4d364372d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   concerned       1.00      0.50      0.67        14\n",
      "   favorable       0.64      0.53      0.58        17\n",
      "     neutral       0.33      0.75      0.46         8\n",
      "\n",
      "    accuracy                           0.56        39\n",
      "   macro avg       0.66      0.59      0.57        39\n",
      "weighted avg       0.71      0.56      0.59        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(metrics.classification_report(df_test1['Actual Sentiment'].tolist(), df_chatgpt_response['Predicted Sentiment'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd589d7f-339e-40ab-80e5-64c3ad203d79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##USING FEW SHOT APPROACH\n",
    "#Favorable, concerned neutral all 3 at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ab3ca98-bd4f-4089-a297-733de971fb55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#########Filter mvocs that are diverse in df_train_for_chatgpt to use as few examples for this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a34d7fa-5daf-4b73-bad6-8fec1c64d1e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(blob_path+'filtered_rsv_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82371af9-849f-45fb-9165-a932e1d3e115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_fews_examples_manual_checked =pd.read_excel(blob_path+'filtered_rsv_sentiments_manual_verified.xlsx', sheet_name=\"rsv_text_manuall_filtered\") #case1#filtered_rsv_sentiments\n",
    "#df_fews_examples_manual_checked =pd.read_excel(blob_path+'filtered_rsv_sentiments_manual_verified.xlsx', sheet_name=\"concerned_neutral_favorable_eq \") #howvere, this even lowers the accuracy because low number of mvocs to learn from\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "df_fews_examples_manual_checked = shuffle(df_fews_examples_manual_checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206f7c58-9a3f-4fb9-9b41-3b02b0c05ec2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_prompt= f\"\"\"Act as a medical expert in USA. Identify the sentiment in a mvoc_stmt based on the examples provided in the next message and the output should only be from the list of sentiments mentioned in sentiment_list, separated by comma. \n",
    "  \n",
    "  Sentiment List: ```{sentiment_list} ```\\\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "for index, row in df_fews_examples_manual_checked.iloc[-40:].iterrows(): # \n",
    "#for index, row in df_fews_examples_manual_checked.iloc[-30:].iterrows(): #considering equal number tabbed sheets\n",
    "  text= row['text']\n",
    "  sent=\"\"\n",
    "  if row['safety_favorable: 703']==1:\n",
    "      sent = 'favorable'\n",
    "  elif row['safety_neutral: 702']==1:\n",
    "      sent = 'neutral'\n",
    "  elif row['safety_concerned: 701']==1:\n",
    "      sent = 'concerned'\n",
    "\n",
    "  \n",
    "  prompt = f\"\"\" mVOC{index} : {text} \\\n",
    "                Sentiment: {sent}\\\n",
    "              \"\"\"\n",
    "              \n",
    "\n",
    "  system_prompt += f\"{prompt}\"\n",
    "\n",
    "system_prompt += \"Be precise. Do not add any information which is not present in the data. Cross-check your answer before for accuracy and logical consitency\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "951c5b0b-f9a5-4305-82f2-acd47f28975c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fewshot_response= pd.DataFrame()\n",
    "for index, row in df_test.iterrows():\n",
    "\n",
    "  user_prompt= f\"\"\" \n",
    "                    mVOC: {row['text']} \\\n",
    "                    Sentiment: <SENTIMENT>\n",
    "\n",
    "\n",
    "\n",
    "              \"\"\"\n",
    "\n",
    "  response= annotater.question_answer(system_prompt, user_prompt)\n",
    "\n",
    "  df_fewshot_response.at[index,'Text']= row['text']\n",
    "  df_fewshot_response.at[index,'Predicted Sentiment']=response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df57159e-a970-4fef-8d6b-cdd6c472dba9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_fewshot_response['Predicted Sentiment'] = df_fewshot_response['Predicted Sentiment'].str.replace('Sentiment: ', \"\")\n",
    "df_fewshot_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a868d1-2225-4f5a-a3d7-4738b7c93a5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "actual_list=df_test1['Actual Sentiment'].tolist()\n",
    "predicted_list=df_fewshot_response['Predicted Sentiment'].tolist()\n",
    "actual_list = [item.lower() for  item in actual_list]\n",
    "predicted_list = [item.lower() for item in predicted_list]\n",
    "\n",
    "\n",
    "print(metrics.classification_report(actual_list, predicted_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a165acd3-3bb2-4f7c-ae23-03d14d814e5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Extract summary of train samples to use for few shot one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d6e2a6-a463-4297-9004-bd5f75486a25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fews_examples_manual_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ca025531\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! py -m pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Sentiment Analysis",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
